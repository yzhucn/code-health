#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£ç å¥åº·ç›‘æ§ - å‘¨æŠ¥ç”Ÿæˆå™¨
Author: DevOps Team
Created: 2025-12-30

Usage:
    python weekly-report.py [week]

Examples:
    python weekly-report.py                 # ç”Ÿæˆæœ¬å‘¨çš„å‘¨æŠ¥
    python weekly-report.py 2025-W52        # ç”ŸæˆæŒ‡å®šå‘¨çš„å‘¨æŠ¥
"""

import os
import sys
from datetime import datetime, timedelta
from collections import defaultdict

# æ·»åŠ è„šæœ¬ç›®å½•åˆ°è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, script_dir)

from utils import (
    GitAnalyzer, ChurnAnalyzer, ReworkAnalyzer, HotspotAnalyzer,
    HealthScoreCalculator, load_config, format_number,
    is_late_night, is_weekend, calculate_message_quality,
    parse_iso_datetime
)


class WeeklyReportGenerator:
    """å‘¨æŠ¥ç”Ÿæˆå™¨"""

    def __init__(self, config_path: str, week_str: str = None):
        self.config = load_config(config_path)

        # è§£æå‘¨æœŸ
        if week_str:
            # æ ¼å¼: 2025-W52
            year, week = week_str.split('-W')
            self.year = int(year)
            self.week = int(week)
        else:
            # ä½¿ç”¨å½“å‰å‘¨
            now = datetime.now()
            self.year = now.year
            self.week = now.isocalendar()[1]

        self.week_str = f"{self.year}-W{self.week:02d}"

        # è®¡ç®—å‘¨çš„èµ·å§‹å’Œç»“æŸæ—¶é—´
        # ISO 8601: å‘¨ä¸€æ˜¯ä¸€å‘¨çš„ç¬¬ä¸€å¤©
        jan4 = datetime(self.year, 1, 4)  # 1æœˆ4æ—¥æ€»æ˜¯åœ¨ç¬¬ä¸€å‘¨
        week1_monday = jan4 - timedelta(days=jan4.weekday())
        week_start = week1_monday + timedelta(weeks=self.week - 1)
        week_end = week_start + timedelta(days=7)

        self.since_time = week_start.strftime("%Y-%m-%d 00:00:00")
        self.until_time = week_end.strftime("%Y-%m-%d 00:00:00")

        # ä¿å­˜æ—¥æœŸèŒƒå›´ç”¨äºæ˜¾ç¤ºï¼ˆå‘¨æ—¥æ˜¯æœ€åä¸€å¤©ï¼‰
        self.week_start_date = week_start
        self.week_end_date = week_start + timedelta(days=6)  # å‘¨ä¸€+6å¤©=å‘¨æ—¥
        self.date_range_str = f"{self.week_start_date.strftime('%mæœˆ%dæ—¥')} - {self.week_end_date.strftime('%mæœˆ%dæ—¥')}"

        self.analyzers = self._init_analyzers()

    def _init_analyzers(self) -> list:
        """åˆå§‹åŒ–æ‰€æœ‰ä»“åº“çš„åˆ†æå™¨"""
        analyzers = []
        for repo in self.config['repositories']:
            if os.path.exists(repo['path']):
                git_analyzer = GitAnalyzer(repo['path'])
                analyzers.append({
                    'name': repo['name'],
                    'type': repo['type'],
                    'git': git_analyzer,
                    'churn': ChurnAnalyzer(
                        git_analyzer,
                        self.config['thresholds']['churn_days'],
                        self.config['thresholds']['churn_count']
                    ),
                    'rework': ReworkAnalyzer(
                        git_analyzer,
                        self.config['thresholds']['rework_add_days'],
                        self.config['thresholds']['rework_delete_days']
                    ),
                    'hotspot': HotspotAnalyzer(
                        git_analyzer,
                        self.config['thresholds']
                    )
                })
        return analyzers

    def generate(self) -> str:
        """ç”Ÿæˆå‘¨æŠ¥"""
        report = []

        # æ ‡é¢˜
        report.append(self._generate_header())

        # ä¸€ã€ç”Ÿäº§åŠ›ç»Ÿè®¡
        report.append("## ä¸€ã€ç”Ÿäº§åŠ›ç»Ÿè®¡ ğŸ“Š")
        report.append(self._generate_productivity())

        # äºŒã€é«˜å±æ–‡ä»¶æ·±åº¦åˆ†æ
        report.append("## äºŒã€é«˜å±æ–‡ä»¶æ·±åº¦åˆ†æ ğŸš¨")
        report.append(self._generate_risk_files())

        # ä¸‰ã€å›¢é˜Ÿå¥åº·åº¦åˆ†æ
        report.append("## ä¸‰ã€å›¢é˜Ÿå¥åº·åº¦åˆ†æ ğŸ‘¥")
        report.append(self._generate_team_health())

        # å››ã€ä»£ç è´¨é‡è¶‹åŠ¿
        report.append("## å››ã€ä»£ç è´¨é‡è¶‹åŠ¿ ğŸ“ˆ")
        report.append(self._generate_quality_trends())

        # äº”ã€æ”¹è¿›å»ºè®®
        report.append("## äº”ã€æ”¹è¿›å»ºè®® ğŸ’¡")
        report.append(self._generate_recommendations())

        # åº•éƒ¨
        report.append(self._generate_footer())

        return '\n\n'.join(report)

    def _generate_header(self) -> str:
        """ç”ŸæˆæŠ¥å‘Šå¤´éƒ¨"""
        lines = [
            f"# ä»£ç å¥åº·å‘¨æŠ¥",
            "",
            f"**æŠ¥å‘Šå‘¨æœŸ**: {self.week_str} ({self.date_range_str})",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "---"
        ]
        return '\n'.join(lines)

    def _generate_productivity(self) -> str:
        """ç”Ÿæˆç”Ÿäº§åŠ›ç»Ÿè®¡"""
        lines = []

        # æ”¶é›†æœ¬å‘¨æ‰€æœ‰æäº¤
        all_commits = []
        for analyzer in self.analyzers:
            commits = analyzer['git'].get_commits(self.since_time, self.until_time)
            for commit in commits:
                all_commits.append({
                    **commit,
                    'repo': analyzer['name']
                })

        # æŒ‰ä½œè€…ç»Ÿè®¡
        author_stats = defaultdict(lambda: {
            'commits': 0,
            'added': 0,
            'deleted': 0,
            'files': 0,
            'repos': set(),
            'languages': defaultdict(int)
        })

        for commit in all_commits:
            author = commit['author']
            author_stats[author]['commits'] += 1
            author_stats[author]['added'] += commit['lines_added']
            author_stats[author]['deleted'] += commit['lines_deleted']
            author_stats[author]['files'] += len(commit['files'])
            author_stats[author]['repos'].add(commit['repo'])

            # ç»Ÿè®¡è¯­è¨€ï¼ˆåŸºäºæ–‡ä»¶æ‰©å±•åï¼‰
            for file_info in commit['files']:
                filepath = file_info['path']
                if filepath.endswith('.java'):
                    author_stats[author]['languages']['Java'] += file_info['added']
                elif filepath.endswith('.py'):
                    author_stats[author]['languages']['Python'] += file_info['added']
                elif filepath.endswith(('.vue', '.js', '.ts')):
                    author_stats[author]['languages']['Vue/JS'] += file_info['added']
                elif filepath.endswith('.dart'):
                    author_stats[author]['languages']['Dart'] += file_info['added']

        # 1. æäº¤é‡æ’è¡Œæ¦œ
        lines.append("### 1ï¸âƒ£ æäº¤é‡æ’è¡Œæ¦œ")
        lines.append("")
        lines.append("| æ’å | å¼€å‘è€… | æäº¤æ¬¡æ•° | æ–°å¢è¡Œæ•° | åˆ é™¤è¡Œæ•° | å‡€å¢è¡Œæ•° | æ–‡ä»¶æ•° | å¹³å‡æäº¤å¤§å° | æ¶‰åŠä»“åº“ |")
        lines.append("|------|--------|---------|---------|---------|---------|--------|------------|----------|")

        # æŒ‰å‡€å¢è¡Œæ•°æ’åº
        sorted_authors = sorted(
            author_stats.items(),
            key=lambda x: x[1]['added'] - x[1]['deleted'],
            reverse=True
        )

        for rank, (author, stats) in enumerate(sorted_authors, 1):
            net = stats['added'] - stats['deleted']
            avg_commit_size = (stats['added'] + stats['deleted']) // stats['commits'] if stats['commits'] > 0 else 0
            repos_count = len(stats['repos'])

            lines.append(
                f"| {rank} | {author} | {stats['commits']} | "
                f"+{format_number(stats['added'])} | "
                f"-{format_number(stats['deleted'])} | "
                f"**{'+' if net >= 0 else ''}{format_number(net)}** | "
                f"{stats['files']} | "
                f"{format_number(avg_commit_size)}è¡Œ/æ¬¡ | "
                f"{repos_count}ä¸ª |"
            )

        lines.append("")

        # 2. LOC è¯¦ç»†ç»Ÿè®¡
        lines.append("### 2ï¸âƒ£ LOC ç»Ÿè®¡ï¼ˆä»£ç è´¡çŒ®è¯¦æƒ…ï¼‰")
        lines.append("")

        for author, stats in sorted_authors:
            net = stats['added'] - stats['deleted']
            efficiency = (net / stats['added'] * 100) if stats['added'] > 0 else 0

            lines.append(f"#### ğŸ‘¤ {author}")
            lines.append("")
            lines.append(f"**ä»£ç è´¡çŒ®**:")
            lines.append(f"- æ–°å¢ä»£ç : {format_number(stats['added'])} è¡Œ")
            lines.append(f"- åˆ é™¤ä»£ç : {format_number(stats['deleted'])} è¡Œ")
            lines.append(f"- å‡€è´¡çŒ®: **{'+' if net >= 0 else ''}{format_number(net)}** è¡Œ")
            lines.append(f"- æœ‰æ•ˆä»£ç ç‡: {efficiency:.1f}% (å‡€å¢/æ–°å¢)")
            lines.append("")

            # è¯­è¨€åˆ†å¸ƒ
            if stats['languages']:
                total_lang_lines = sum(stats['languages'].values())
                lines.append("**ä¸»è¦è¯­è¨€**:")
                for lang, lines_count in sorted(stats['languages'].items(), key=lambda x: x[1], reverse=True):
                    percentage = (lines_count / total_lang_lines * 100) if total_lang_lines > 0 else 0
                    lines.append(f"- {lang}: {format_number(lines_count)} è¡Œ ({percentage:.0f}%)")
                lines.append("")

            # æ¶‰åŠä»“åº“
            lines.append(f"**æ¶‰åŠä»“åº“**: {', '.join(sorted(stats['repos']))}")
            lines.append("")

        # 3. å›¢é˜Ÿæ€»äº§å‡º
        total_commits = len(all_commits)
        total_added = sum(c['lines_added'] for c in all_commits)
        total_deleted = sum(c['lines_deleted'] for c in all_commits)
        total_net = total_added - total_deleted
        avg_efficiency = (total_net / total_added * 100) if total_added > 0 else 0

        lines.append("### 3ï¸âƒ£ å›¢é˜Ÿæ€»äº§å‡º")
        lines.append("")
        lines.append("| æŒ‡æ ‡ | æ•°å€¼ |")
        lines.append("|------|------|")
        lines.append(f"| æ€»æäº¤æ•° | {total_commits} æ¬¡ |")
        lines.append(f"| æ€»æ–°å¢è¡Œæ•° | +{format_number(total_added)} è¡Œ |")
        lines.append(f"| æ€»åˆ é™¤è¡Œæ•° | -{format_number(total_deleted)} è¡Œ |")
        lines.append(f"| **æ€»å‡€å¢è¡Œæ•°** | **+{format_number(total_net)}** è¡Œ |")
        lines.append(f"| å¹³å‡æœ‰æ•ˆç‡ | {avg_efficiency:.1f}% |")
        lines.append(f"| æ´»è·ƒå¼€å‘è€… | {len(author_stats)} äºº |")
        lines.append("")

        # 4. ä»“åº“ LOC åˆ†å¸ƒ
        lines.append("### 4ï¸âƒ£ ä»“åº“ LOC åˆ†å¸ƒ")
        lines.append("")

        repo_stats = defaultdict(lambda: {'added': 0, 'deleted': 0, 'commits': 0})
        for commit in all_commits:
            repo = commit['repo']
            repo_stats[repo]['added'] += commit['lines_added']
            repo_stats[repo]['deleted'] += commit['lines_deleted']
            repo_stats[repo]['commits'] += 1

        lines.append("| ä»“åº“ | æäº¤ | æ–°å¢ | åˆ é™¤ | å‡€å¢ | å æ¯” |")
        lines.append("|------|------|------|------|------|------|")

        sorted_repos = sorted(
            repo_stats.items(),
            key=lambda x: x[1]['added'] - x[1]['deleted'],
            reverse=True
        )

        for repo, stats in sorted_repos:
            net = stats['added'] - stats['deleted']
            percentage = (net / total_net * 100) if total_net > 0 else 0
            lines.append(
                f"| {repo} | {stats['commits']} | "
                f"+{format_number(stats['added'])} | "
                f"-{format_number(stats['deleted'])} | "
                f"**+{format_number(net)}** | "
                f"{percentage:.0f}% |"
            )

        lines.append("")

        return '\n'.join(lines)

    def _generate_risk_files(self) -> str:
        """ç”Ÿæˆé«˜å±æ–‡ä»¶åˆ†æ"""
        lines = []

        # æ”¶é›†æ‰€æœ‰é«˜å±æ–‡ä»¶
        all_hotspots = []
        for analyzer in self.analyzers:
            hotspots = analyzer['hotspot'].analyze()
            all_hotspots.extend([{**h, 'repo': analyzer['name']} for h in hotspots])

        all_hotspots.sort(key=lambda x: x['risk_score'], reverse=True)

        # ç»Ÿè®¡é£é™©ç­‰çº§
        critical_count = len([h for h in all_hotspots if h['risk_score'] >= 80])
        high_count = len([h for h in all_hotspots if 60 <= h['risk_score'] < 80])
        medium_count = len([h for h in all_hotspots if 40 <= h['risk_score'] < 60])

        lines.append("### 1ï¸âƒ£ é£é™©æ¦‚è§ˆ")
        lines.append("")
        lines.append(f"**å‘ç°é«˜å±æ–‡ä»¶**: {len(all_hotspots)} ä¸ª")
        lines.append("")
        lines.append("| é£é™©ç­‰çº§ | æ•°é‡ | è¯´æ˜ |")
        lines.append("|---------|------|------|")
        lines.append(f"| ğŸ”´ ä¸¥é‡ (80-100) | {critical_count} | éœ€è¦ç«‹å³é‡æ„ |")
        lines.append(f"| ğŸŸ  é«˜ (60-79) | {high_count} | æœ¬å‘¨å†…å¤„ç† |")
        lines.append(f"| ğŸŸ¡ ä¸­ (40-59) | {medium_count} | è®¡åˆ’æ”¹è¿› |")
        lines.append("")

        # TOP 20 é«˜å±æ–‡ä»¶
        lines.append("### 2ï¸âƒ£ é«˜å±æ–‡ä»¶ TOP 20")
        lines.append("")
        lines.append("| æ’å | ä»“åº“ | æ–‡ä»¶ | é£é™©åˆ† | ä¿®æ”¹æ¬¡æ•° | å¤§å° | å¼€å‘è€… | é£é™©æ ‡ç­¾ | å»ºè®® |")
        lines.append("|------|------|------|--------|---------|------|--------|----------|------|")

        for rank, h in enumerate(all_hotspots[:20], 1):
            risk_emoji = "ğŸ”´" if h['risk_score'] >= 80 else "ğŸŸ " if h['risk_score'] >= 60 else "ğŸŸ¡"
            tags = ', '.join(h['tags']) if h['tags'] else "-"
            suggestion_icon = h['suggestion'].split()[0]  # æå–emoji

            lines.append(
                f"| {rank} | {h['repo']} | `{h['file']}` | "
                f"{risk_emoji} {h['risk_score']:.0f} | "
                f"{h['modify_count']} | {h['file_size']} è¡Œ | "
                f"{h['author_count']}äºº | {tags} | {suggestion_icon} |"
            )

        lines.append("")

        # é£é™©æ–‡ä»¶è¯¦ç»†åˆ†æ
        if critical_count > 0:
            lines.append("### 3ï¸âƒ£ ä¸¥é‡é£é™©æ–‡ä»¶è¯¦æƒ…")
            lines.append("")

            for h in all_hotspots[:5]:
                if h['risk_score'] < 80:
                    break

                lines.append(f"#### ğŸ”´ {h['repo']}: `{h['file']}`")
                lines.append("")
                lines.append(f"**é£é™©åˆ†æ•°**: {h['risk_score']:.0f} / 100")
                lines.append(f"**æœ€è¿‘7å¤©ä¿®æ”¹**: {h['modify_count']} æ¬¡")
                lines.append(f"**æ–‡ä»¶å¤§å°**: {h['file_size']} è¡Œ")
                lines.append(f"**æ¶‰åŠå¼€å‘è€…**: {', '.join(h['authors'])}")
                lines.append(f"**é£é™©æ ‡ç­¾**: {', '.join(h['tags'])}")
                lines.append("")
                lines.append(f"**æ”¹è¿›å»ºè®®**: {h['suggestion']}")
                lines.append("")

        return '\n'.join(lines)

    def _generate_team_health(self) -> str:
        """ç”Ÿæˆå›¢é˜Ÿå¥åº·åº¦åˆ†æ"""
        lines = []

        # æ”¶é›†æœ¬å‘¨æ‰€æœ‰æäº¤
        all_commits = []
        for analyzer in self.analyzers:
            commits = analyzer['git'].get_commits(self.since_time, self.until_time)
            for commit in commits:
                all_commits.append({
                    **commit,
                    'repo': analyzer['name']
                })

        # 1. å·¥ä½œæ¨¡å¼åˆ†æ
        lines.append("### 1ï¸âƒ£ å·¥ä½œæ—¶é—´åˆ†å¸ƒ")
        lines.append("")

        # ç»Ÿè®¡æ¯ä¸ªæ—¶æ®µçš„æäº¤
        time_slots = defaultdict(int)
        weekday_commits = 0
        weekend_commits = 0
        late_night_commits = 0

        for commit in all_commits:
            try:
                dt = parse_iso_datetime(commit['date'])
                hour = dt.hour

                # æ—¶æ®µåˆ†ç±»
                if 0 <= hour < 6:
                    time_slots['00-06'] += 1
                    late_night_commits += 1
                elif 6 <= hour < 9:
                    time_slots['06-09'] += 1
                elif 9 <= hour < 12:
                    time_slots['09-12'] += 1
                elif 12 <= hour < 14:
                    time_slots['12-14'] += 1
                elif 14 <= hour < 18:
                    time_slots['14-18'] += 1
                elif 18 <= hour < 22:
                    time_slots['18-22'] += 1
                else:
                    time_slots['22-24'] += 1
                    late_night_commits += 1

                # å·¥ä½œæ—¥ vs å‘¨æœ«
                if is_weekend(commit['date']):
                    weekend_commits += 1
                else:
                    weekday_commits += 1
            except:
                pass

        total_commits = len(all_commits)

        lines.append("**æ—¶æ®µåˆ†å¸ƒçƒ­åŠ›å›¾** (æœ¬å‘¨):")
        lines.append("```")
        for slot in ['00-06', '06-09', '09-12', '12-14', '14-18', '18-22', '22-24']:
            count = time_slots.get(slot, 0)
            percentage = (count / total_commits * 100) if total_commits > 0 else 0
            bar_length = int(percentage / 3)
            bar = 'â–ˆ' * bar_length + 'â–‘' * (33 - bar_length)

            slot_name = {
                '00-06': 'æ·±å¤œ',
                '06-09': 'æ—©æ™¨',
                '09-12': 'ä¸Šåˆ',
                '12-14': 'åˆä¼‘',
                '14-18': 'ä¸‹åˆ',
                '18-22': 'æ™šä¸Š',
                '22-24': 'æ·±å¤œ'
            }[slot]

            lines.append(f"{slot} ({slot_name}): {bar} {percentage:5.1f}% ({count}æ¬¡)")
        lines.append("```")
        lines.append("")

        # å·¥ä½œæ—¥ vs å‘¨æœ«
        weekday_pct = (weekday_commits / total_commits * 100) if total_commits > 0 else 0
        weekend_pct = (weekend_commits / total_commits * 100) if total_commits > 0 else 0

        lines.append("**å·¥ä½œæ—¥ vs å‘¨æœ«**:")
        lines.append(f"- å·¥ä½œæ—¥æäº¤: {weekday_commits} æ¬¡ ({weekday_pct:.0f}%)")
        lines.append(f"- å‘¨æœ«æäº¤: {weekend_commits} æ¬¡ ({weekend_pct:.0f}%)")
        lines.append("")

        # å¥åº·è¯„ä¼°
        late_night_pct = (late_night_commits / total_commits * 100) if total_commits > 0 else 0

        if late_night_pct > 20 or weekend_pct > 20:
            health_status = "ğŸ”´ éœ€è¦å…³æ³¨"
            suggestion = "æ·±å¤œ/å‘¨æœ«æäº¤å æ¯”è¾ƒé«˜ï¼Œå»ºè®®å…³æ³¨å›¢é˜Ÿå·¥ä½œå‹åŠ›å’Œæ’æœŸåˆç†æ€§"
        elif late_night_pct > 10 or weekend_pct > 10:
            health_status = "ğŸŸ¡ ä¸­ç­‰"
            suggestion = "æœ‰ä¸€å®šæ·±å¤œ/å‘¨æœ«å·¥ä½œï¼Œå»ºè®®é€‚å½“ä¼˜åŒ–å·¥ä½œå®‰æ’"
        else:
            health_status = "ğŸŸ¢ å¥åº·"
            suggestion = "å·¥ä½œæ—¶é—´åˆ†å¸ƒåˆç†ï¼Œä¿æŒè‰¯å¥½å·¥ä½œèŠ‚å¥"

        lines.append(f"**å¥åº·è¯„ä¼°**: {health_status}")
        lines.append(f"**å»ºè®®**: {suggestion}")
        lines.append("")

        # 2. æäº¤èŠ‚å¥åˆ†æ
        lines.append("### 2ï¸âƒ£ æäº¤èŠ‚å¥åˆ†æ")
        lines.append("")

        author_commit_counts = defaultdict(int)
        for commit in all_commits:
            author_commit_counts[commit['author']] += 1

        lines.append("| å¼€å‘è€… | æäº¤æ¬¡æ•° | èŠ‚å¥è¯„ä»· |")
        lines.append("|--------|---------|----------|")

        for author, count in sorted(author_commit_counts.items(), key=lambda x: x[1], reverse=True):
            daily_avg = count / 7

            if daily_avg >= 5:
                rhythm = "ğŸŸ¢ ç¨³å®šé«˜é¢‘"
            elif daily_avg >= 2:
                rhythm = "ğŸŸ¢ ç¨³å®šé€‚ä¸­"
            elif daily_avg >= 1:
                rhythm = "ğŸŸ¡ è¾ƒä¸ºé›¶æ•£"
            else:
                rhythm = "ğŸ”´ ä¸è§„å¾‹"

            lines.append(f"| {author} | {count} æ¬¡ (æ—¥å‡{daily_avg:.1f}) | {rhythm} |")

        lines.append("")

        # 3. åä½œçƒ­åŠ›å›¾
        lines.append("### 3ï¸âƒ£ åä½œå…³ç³»åˆ†æ")
        lines.append("")

        # æ‰¾å‡ºå…±åŒä¿®æ”¹çš„æ–‡ä»¶
        file_authors = defaultdict(set)
        for commit in all_commits:
            for file_info in commit['files']:
                file_authors[file_info['path']].add(commit['author'])

        # ç»Ÿè®¡åä½œå…³ç³»ï¼ˆå…±åŒä¿®æ”¹æ–‡ä»¶æ•°ï¼‰
        authors = list(author_commit_counts.keys())
        collaboration = defaultdict(lambda: defaultdict(int))

        for filepath, author_set in file_authors.items():
            if len(author_set) > 1:
                author_list = list(author_set)
                for i, a1 in enumerate(author_list):
                    for a2 in author_list[i+1:]:
                        collaboration[a1][a2] += 1
                        collaboration[a2][a1] += 1

        if collaboration:
            lines.append("**åä½œçƒ­åŠ›å›¾** (å…±åŒä¿®æ”¹æ–‡ä»¶æ•°):")
            lines.append("")

            # è¡¨å¤´
            header = "| å¼€å‘è€… |"
            for author in authors[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                header += f" {author[:8]} |"
            lines.append(header)

            separator = "|--------|"
            for _ in authors[:5]:
                separator += "--------|"
            lines.append(separator)

            # æ•°æ®
            for a1 in authors[:5]:
                row = f"| {a1[:8]} |"
                for a2 in authors[:5]:
                    if a1 == a2:
                        row += " - |"
                    else:
                        count = collaboration[a1].get(a2, 0)
                        if count > 10:
                            row += f" **{count}** |"
                        elif count > 5:
                            row += f" {count} |"
                        else:
                            row += f" {count if count > 0 else '-'} |"
                lines.append(row)

            lines.append("")
            lines.append("**åˆ†æ**:")

            # æ‰¾å‡ºåä½œæœ€å¯†åˆ‡çš„pair
            max_collab = 0
            max_pair = None
            for a1 in collaboration:
                for a2, count in collaboration[a1].items():
                    if count > max_collab:
                        max_collab = count
                        max_pair = (a1, a2)

            if max_pair:
                lines.append(f"- **æœ€å¯†åˆ‡åä½œ**: {max_pair[0]} & {max_pair[1]} (å…±åŒä¿®æ”¹ {max_collab} ä¸ªæ–‡ä»¶)")
                lines.append(f"- **å»ºè®®**: å®šæœŸåŒæ­¥æ²Ÿé€šï¼Œå»ºç«‹ä»£ç è§„èŒƒï¼Œé¿å…ä»£ç å†²çª")
        else:
            lines.append("æœ¬å‘¨æ— æ˜æ˜¾åä½œå…³ç³»ï¼ˆå¼€å‘è€…ç‹¬ç«‹å·¥ä½œï¼‰")

        lines.append("")

        return '\n'.join(lines)

    def _generate_quality_trends(self) -> str:
        """ç”Ÿæˆä»£ç è´¨é‡è¶‹åŠ¿"""
        lines = []

        # è®¡ç®—æœ¬å‘¨çš„éœ‡è¡ç‡å’Œè¿”å·¥ç‡
        total_churn_rate = 0
        total_rework_rate = 0
        repo_count = 0

        all_churn_files = []
        total_rework = 0
        total_added = 0

        for analyzer in self.analyzers:
            churn_files, churn_rate = analyzer['churn'].analyze()
            rework_lines, added_lines, rework_rate = analyzer['rework'].analyze()

            total_churn_rate += churn_rate
            total_rework_rate += rework_rate
            all_churn_files.extend(churn_files)
            total_rework += rework_lines
            total_added += added_lines
            repo_count += 1

        avg_churn_rate = total_churn_rate / repo_count if repo_count > 0 else 0
        avg_rework_rate = total_rework_rate / repo_count if repo_count > 0 else 0

        # 1. éœ‡è¡ç‡è¶‹åŠ¿
        lines.append("### 1ï¸âƒ£ ä»£ç éœ‡è¡ç‡")
        lines.append("")
        lines.append(f"**æœ¬å‘¨éœ‡è¡ç‡**: {avg_churn_rate:.1f}%")

        if avg_churn_rate >= 30:
            status = "ğŸ”´ é«˜é£é™©"
            advice = "éœ‡è¡ç‡è¿‡é«˜ï¼Œè¡¨æ˜ä»£ç è®¾è®¡ä¸ç¨³å®šï¼Œå»ºè®®è¿›è¡Œæ¶æ„review"
        elif avg_churn_rate >= 10:
            status = "ğŸŸ¡ ä¸­é£é™©"
            advice = "éœ‡è¡ç‡åé«˜ï¼Œå»ºè®®ç¨³å®šæ ¸å¿ƒæ¥å£ï¼Œå‡å°‘é¢‘ç¹ä¿®æ”¹"
        else:
            status = "ğŸŸ¢ ä½é£é™©"
            advice = "éœ‡è¡ç‡æ­£å¸¸ï¼Œä»£ç ç›¸å¯¹ç¨³å®š"

        lines.append(f"**çŠ¶æ€**: {status}")
        lines.append(f"**å»ºè®®**: {advice}")
        lines.append("")

        if all_churn_files:
            lines.append(f"**éœ‡è¡æ–‡ä»¶**: {len(all_churn_files)} ä¸ª")
            lines.append("")

        # 2. è¿”å·¥ç‡è¶‹åŠ¿
        lines.append("### 2ï¸âƒ£ ä»£ç è¿”å·¥ç‡")
        lines.append("")
        lines.append(f"**æœ¬å‘¨è¿”å·¥ç‡**: {avg_rework_rate:.1f}%")
        lines.append(f"**è¿”å·¥ä»£ç é‡**: {format_number(total_rework)} è¡Œ")

        if avg_rework_rate >= 30:
            status = "ğŸ”´ é«˜é£é™©"
            advice = "è¿”å·¥ç‡è¿‡é«˜ï¼Œå»ºè®®åŠ å¼ºéœ€æ±‚è¯„å®¡å’Œè®¾è®¡é˜¶æ®µæŠ•å…¥"
        elif avg_rework_rate >= 15:
            status = "ğŸŸ¡ ä¸­é£é™©"
            advice = "æœ‰ä¸€å®šè¿”å·¥ï¼Œå»ºè®®æé«˜æµ‹è¯•è¦†ç›–ç‡å’Œä»£ç å®¡æŸ¥è´¨é‡"
        else:
            status = "ğŸŸ¢ ä½é£é™©"
            advice = "è¿”å·¥ç‡è¾ƒä½ï¼Œä»£ç è´¨é‡è¾ƒå¥½"

        lines.append(f"**çŠ¶æ€**: {status}")
        lines.append(f"**å»ºè®®**: {advice}")
        lines.append("")

        # 3. æäº¤è´¨é‡åˆ†æ
        lines.append("### 3ï¸âƒ£ æäº¤è´¨é‡")
        lines.append("")

        all_commits = []
        large_commits = 0
        tiny_commits = 0

        for analyzer in self.analyzers:
            commits = analyzer['git'].get_commits(self.since_time, self.until_time)
            all_commits.extend(commits)

            for commit in commits:
                total_change = commit['lines_added'] + commit['lines_deleted']
                if total_change > self.config['thresholds']['large_commit']:
                    large_commits += 1
                elif total_change < self.config['thresholds']['tiny_commit']:
                    tiny_commits += 1

        message_quality = calculate_message_quality(all_commits)

        lines.append("| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |")
        lines.append("|------|------|------|")
        lines.append(f"| å¤§æäº¤ (>{self.config['thresholds']['large_commit']}è¡Œ) | {large_commits} æ¬¡ | "
                    f"{'ğŸ”´ éœ€æ”¹è¿›' if large_commits > 5 else 'ğŸŸ¢ æ­£å¸¸'} |")
        lines.append(f"| å¾®å°æäº¤ (<{self.config['thresholds']['tiny_commit']}è¡Œ) | {tiny_commits} æ¬¡ | "
                    f"{'ğŸŸ¡ å…³æ³¨' if tiny_commits > 10 else 'ğŸŸ¢ æ­£å¸¸'} |")
        lines.append(f"| æäº¤ä¿¡æ¯è´¨é‡ | {message_quality:.0f}% | "
                    f"{'ğŸ”´ å·®' if message_quality < 60 else 'ğŸŸ¡ ä¸­' if message_quality < 80 else 'ğŸŸ¢ å¥½'} |")
        lines.append("")

        # 4. æŠ€æœ¯å€ºåŠ¡æŒ‡æ ‡
        lines.append("### 4ï¸âƒ£ æŠ€æœ¯å€ºåŠ¡")
        lines.append("")

        # ç»Ÿè®¡é«˜å±æ–‡ä»¶æ•°é‡
        high_risk_count = 0
        for analyzer in self.analyzers:
            hotspots = analyzer['hotspot'].analyze()
            high_risk_count += len([h for h in hotspots if h['risk_score'] >= 60])

        lines.append("| æŒ‡æ ‡ | æ•°å€¼ | è¶‹åŠ¿ |")
        lines.append("|------|------|------|")
        lines.append(f"| é«˜å±æ–‡ä»¶æ•° | {high_risk_count} ä¸ª | âš ï¸ éœ€å…³æ³¨ |")
        lines.append(f"| ä»£ç é‡å¤ç‡ | ä¼°è®¡ 15% | ğŸ“Š éœ€å·¥å…·æ‰«æ |")
        lines.append(f"| æµ‹è¯•è¦†ç›–ç‡ | ä¼°è®¡ 35% | ğŸ“Š éœ€é›†æˆå·¥å…· |")
        lines.append("")

        debt_status = "âš ï¸ å€ºåŠ¡ç´¯ç§¯ä¸­" if high_risk_count > 10 else "âœ… å¯æ§"
        lines.append(f"**æŠ€æœ¯å€ºåŠ¡çŠ¶æ€**: {debt_status}")
        lines.append("")
        lines.append("**å»ºè®®**: æ¯å‘¨é¢„ç•™ 20% æ—¶é—´å¤„ç†æŠ€æœ¯å€ºåŠ¡ï¼Œé¿å…ç´¯ç§¯")
        lines.append("")

        return '\n'.join(lines)

    def _generate_recommendations(self) -> str:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        lines = []

        # æ”¶é›†æ•°æ®ç”¨äºç”Ÿæˆå»ºè®®
        all_commits = []
        all_hotspots = []

        for analyzer in self.analyzers:
            commits = analyzer['git'].get_commits(self.since_time, self.until_time)
            all_commits.extend(commits)

            hotspots = analyzer['hotspot'].analyze()
            all_hotspots.extend([{**h, 'repo': analyzer['name']} for h in hotspots])

        # ç»Ÿè®¡æŒ‡æ ‡
        critical_files = [h for h in all_hotspots if h['risk_score'] >= 80]
        high_files = [h for h in all_hotspots if 60 <= h['risk_score'] < 80]

        large_commits = sum(1 for c in all_commits
                           if c['lines_added'] + c['lines_deleted'] > self.config['thresholds']['large_commit'])

        message_quality = calculate_message_quality(all_commits)

        late_night = sum(1 for c in all_commits if is_late_night(c['date'], self.config))
        weekend = sum(1 for c in all_commits if is_weekend(c['date']))

        # 1. å³æ—¶è¡ŒåŠ¨é¡¹
        lines.append("### 1ï¸âƒ£ å³æ—¶è¡ŒåŠ¨é¡¹ï¼ˆæœ¬å‘¨å®Œæˆï¼‰")
        lines.append("")

        immediate_actions = []

        if critical_files:
            immediate_actions.append({
                'priority': 'ğŸ”´ é«˜ä¼˜å…ˆçº§',
                'task': f'é‡æ„ä¸¥é‡é£é™©æ–‡ä»¶ TOP 3',
                'detail': f"- {critical_files[0]['repo']}: `{critical_files[0]['file']}` (é£é™©åˆ†: {critical_files[0]['risk_score']:.0f})\n  å»ºè®®: {critical_files[0]['suggestion']}"
            })

        if message_quality < 60:
            immediate_actions.append({
                'priority': 'ğŸ”´ é«˜ä¼˜å…ˆçº§',
                'task': 'è§„èŒƒæäº¤ä¿¡æ¯æ ¼å¼',
                'detail': '- ä½¿ç”¨è§„èŒƒæ ¼å¼: feat/fix/refactor/docs(scope): description\n  ç¤ºä¾‹: feat(kb): æ–°å¢æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½'
            })

        if large_commits > 5:
            immediate_actions.append({
                'priority': 'ğŸŸ  ä¸­ä¼˜å…ˆçº§',
                'task': 'æ§åˆ¶æäº¤ç²’åº¦',
                'detail': f'- æœ¬å‘¨æœ‰ {large_commits} æ¬¡å¤§æäº¤ (>500è¡Œ)\n  å»ºè®®: å°†å¤§åŠŸèƒ½æ‹†åˆ†ä¸ºå¤šä¸ªå°æäº¤ï¼Œä¾¿äºcode review'
            })

        if not immediate_actions:
            immediate_actions.append({
                'priority': 'ğŸŸ¢ è‰¯å¥½',
                'task': 'ä¿æŒå½“å‰è´¨é‡æ°´å¹³',
                'detail': '- æœ¬å‘¨ä»£ç è´¨é‡è‰¯å¥½ï¼Œç»§ç»­ä¿æŒ'
            })

        for i, action in enumerate(immediate_actions[:3], 1):
            lines.append(f"**{i}. {action['task']}** ({action['priority']})")
            lines.append(action['detail'])
            lines.append("")

        # 2. çŸ­æœŸæ”¹è¿›é¡¹
        lines.append("### 2ï¸âƒ£ çŸ­æœŸæ”¹è¿›é¡¹ï¼ˆæœ¬æœˆå®Œæˆï¼‰")
        lines.append("")

        short_term = []

        if high_files:
            short_term.append("**1. å¤„ç†é«˜é£é™©æ–‡ä»¶**")
            short_term.append(f"   - å‘ç° {len(high_files)} ä¸ªé«˜é£é™©æ–‡ä»¶")
            short_term.append("   - åˆ¶å®šé‡æ„è®¡åˆ’ï¼Œé€æ­¥é™ä½å¤æ‚åº¦")
            short_term.append("")

        short_term.append("**2. å»ºç«‹ Code Review æµç¨‹**")
        short_term.append("   - è‡³å°‘ dev â†’ master éœ€è¦ review")
        short_term.append("   - è®¾ç½® review checklist")
        short_term.append("   - è¦æ±‚è‡³å°‘ 1 äºº approve")
        short_term.append("")

        short_term.append("**3. æå‡æµ‹è¯•è¦†ç›–ç‡**")
        short_term.append("   - å•å…ƒæµ‹è¯•ç›®æ ‡: 60%")
        short_term.append("   - é›†æˆæµ‹è¯•è¦†ç›–æ ¸å¿ƒæµç¨‹")
        short_term.append("   - å¼•å…¥æµ‹è¯•è¦†ç›–ç‡å·¥å…· (JaCoCo/pytest-cov)")
        short_term.append("")

        lines.extend(short_term)

        # 3. é•¿æœŸä¼˜åŒ–é¡¹
        lines.append("### 3ï¸âƒ£ é•¿æœŸä¼˜åŒ–é¡¹ï¼ˆæœ¬å­£åº¦ï¼‰")
        lines.append("")

        long_term = [
            "**1. æ¶æ„ä¼˜åŒ–**",
            "   - è¯„ä¼°å¾®æœåŠ¡æ‹†åˆ†å¯è¡Œæ€§",
            "   - æå–å…¬å…±åº“å’Œå·¥å…·ç±»",
            "   - å»ºç«‹ API ç‰ˆæœ¬ç®¡ç†æœºåˆ¶",
            "",
            "**2. å·¥ç¨‹æ•ˆç‡æå‡**",
            "   - ä¼˜åŒ– CI/CD æµæ°´çº¿",
            "   - å¼•å…¥ä»£ç è´¨é‡å·¥å…· (SonarQube)",
            "   - å»ºç«‹æ€§èƒ½ç›‘æ§ä½“ç³»",
            "",
            "**3. å›¢é˜Ÿèƒ½åŠ›å»ºè®¾**",
            "   - å‰ç«¯æŠ€èƒ½åŸ¹è®­ (Vue 3 æœ€ä½³å®è·µ)",
            "   - TDD å®è·µæ¨å¹¿",
            "   - å®šæœŸæŠ€æœ¯åˆ†äº«å’Œæ–‡æ¡£å»ºè®¾",
            ""
        ]

        lines.extend(long_term)

        # 4. æœ¬å‘¨äº®ç‚¹
        lines.append("### 4ï¸âƒ£ æœ¬å‘¨äº®ç‚¹ âœ¨")
        lines.append("")

        highlights = []

        # æ‰¾å‡ºæœ¬å‘¨æœ€æ´»è·ƒçš„å¼€å‘è€…
        author_commits = defaultdict(int)
        for commit in all_commits:
            author_commits[commit['author']] += 1

        if author_commits:
            top_contributor = max(author_commits.items(), key=lambda x: x[1])
            highlights.append(f"- ğŸ† **æœ€æ´»è·ƒå¼€å‘è€…**: {top_contributor[0]} ({top_contributor[1]} æ¬¡æäº¤)")

        # ä»£ç è´¨é‡äº®ç‚¹
        if message_quality >= 80:
            highlights.append(f"- âœ… **æäº¤ä¿¡æ¯è´¨é‡ä¼˜ç§€**: {message_quality:.0f}%")

        if late_night + weekend < 5:
            highlights.append("- ğŸŒŸ **å·¥ä½œæ—¶é—´å¥åº·**: æ·±å¤œ/å‘¨æœ«æäº¤å°‘ï¼Œå·¥ä½œç”Ÿæ´»å¹³è¡¡è‰¯å¥½")

        if not all_hotspots:
            highlights.append("- ğŸ’ª **ä»£ç è´¨é‡ç¨³å®š**: æœ¬å‘¨æ— é«˜å±æ–‡ä»¶äº§ç”Ÿ")

        for highlight in highlights:
            lines.append(highlight)

        if not highlights:
            lines.append("- ç»§ç»­ä¿æŒï¼ŒæŒç»­æ”¹è¿›")

        lines.append("")

        return '\n'.join(lines)

    def _generate_footer(self) -> str:
        """ç”ŸæˆæŠ¥å‘Šåº•éƒ¨"""
        lines = [
            "---",
            "",
            "**ğŸ“Œ è¯´æ˜**:",
            "- æ•°æ®æ¥æº: Git æäº¤å†å²ï¼ˆæœ€è¿‘ 7 å¤©ï¼‰",
            f"- ç»Ÿè®¡å‘¨æœŸ: {self.week_str}",
            "- æ›´æ–°é¢‘ç‡: æ¯å‘¨è‡ªåŠ¨ç”Ÿæˆ",
            "",
            "**ğŸ¯ ä¸‹å‘¨é‡ç‚¹**:",
            "1. å¤„ç†æœ¬å‘¨å‘ç°çš„é«˜å±æ–‡ä»¶",
            "2. æ”¹è¿›æäº¤è§„èŒƒå’Œä»£ç è´¨é‡",
            "3. æŒç»­å…³æ³¨å›¢é˜Ÿå·¥ä½œå¥åº·åº¦",
            "",
            "*ç”±ä»£ç å¥åº·ç›‘æ§ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*"
        ]
        return '\n'.join(lines)


def main():
    """ä¸»å‡½æ•°"""
    # è·å–é…ç½®æ–‡ä»¶è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    config_path = os.path.join(project_root, 'config.yaml')

    # è·å–å‘¨æœŸå‚æ•°
    week_str = sys.argv[1] if len(sys.argv) > 1 else None

    # ç”ŸæˆæŠ¥å‘Š
    generator = WeeklyReportGenerator(config_path, week_str)
    report = generator.generate()

    # è¾“å‡ºåˆ°æ–‡ä»¶
    output_dir = os.path.join(project_root, 'reports', 'weekly')
    os.makedirs(output_dir, exist_ok=True)

    output_file = os.path.join(output_dir, f'{generator.week_str}.md')
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"âœ… å‘¨æŠ¥å·²ç”Ÿæˆ: {output_file}")

    # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
    print("\n" + "=" * 80 + "\n")
    print(report)


if __name__ == "__main__":
    main()
