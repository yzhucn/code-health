#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£ç å¥åº·ç›‘æ§ - æ—¥æŠ¥ç”Ÿæˆå™¨
Author: DevOps Team
Created: 2025-12-30

Usage:
    python daily-report.py [date]

Examples:
    python daily-report.py                  # ç”Ÿæˆä»Šå¤©çš„æ—¥æŠ¥
    python daily-report.py 2025-12-29       # ç”ŸæˆæŒ‡å®šæ—¥æœŸçš„æ—¥æŠ¥
"""

import os
import sys
from datetime import datetime, timedelta
from collections import defaultdict

# æ·»åŠ è„šæœ¬ç›®å½•åˆ°è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, script_dir)

from utils import (
    GitAnalyzer, ChurnAnalyzer, ReworkAnalyzer, HotspotAnalyzer,
    HealthScoreCalculator, load_config, format_number,
    is_late_night, is_weekend, is_overtime, calculate_message_quality,
    parse_iso_datetime
)


class DailyReportGenerator:
    """æ—¥æŠ¥ç”Ÿæˆå™¨"""

    def __init__(self, config_path: str, report_date: str = None):
        self.config = load_config(config_path)
        self.report_date = report_date or datetime.now().strftime("%Y-%m-%d")

        # è®¡ç®—æŸ¥è¯¢çš„æ—¶é—´èŒƒå›´
        date_obj = datetime.strptime(self.report_date, "%Y-%m-%d")
        self.since_time = date_obj.strftime("%Y-%m-%d 00:00:00")
        self.until_time = (date_obj + timedelta(days=1)).strftime("%Y-%m-%d 00:00:00")

        self.analyzers = self._init_analyzers()

    def _init_analyzers(self) -> list:
        """åˆå§‹åŒ–æ‰€æœ‰ä»“åº“çš„åˆ†æå™¨"""
        analyzers = []
        for repo in self.config['repositories']:
            if os.path.exists(repo['path']):
                git_analyzer = GitAnalyzer(repo['path'])
                analyzers.append({
                    'name': repo['name'],
                    'type': repo['type'],
                    'git': git_analyzer,
                    'churn': ChurnAnalyzer(
                        git_analyzer,
                        self.config['thresholds']['churn_days'],
                        self.config['thresholds']['churn_count']
                    ),
                    'rework': ReworkAnalyzer(
                        git_analyzer,
                        self.config['thresholds']['rework_add_days'],
                        self.config['thresholds']['rework_delete_days']
                    ),
                    'hotspot': HotspotAnalyzer(
                        git_analyzer,
                        self.config['thresholds']
                    )
                })
        return analyzers

    def generate(self) -> str:
        """ç”Ÿæˆæ—¥æŠ¥"""
        report = []

        # æ ‡é¢˜
        report.append(self._generate_header())

        # ä¸€ã€åŸºç¡€æ•°æ®
        report.append("## ä¸€ã€ä»Šæ—¥æ¦‚å†µ")
        report.append(self._generate_basic_metrics())

        # äºŒã€ä»£ç å˜æ›´
        report.append("## äºŒã€ä»£ç å˜æ›´ç»Ÿè®¡")
        report.append(self._generate_code_changes())

        # ä¸‰ã€é£é™©é¢„è­¦
        report.append("## ä¸‰ã€é£é™©é¢„è­¦ ğŸš¨")
        report.append(self._generate_risk_alerts())

        # å››ã€å¥åº·è¯„åˆ†
        report.append("## å››ã€ä»Šæ—¥å¥åº·è¯„åˆ†")
        report.append(self._generate_health_score())

        # äº”ã€æäº¤è¯¦æƒ…
        report.append("## äº”ã€æäº¤è¯¦æƒ…")
        report.append(self._generate_commit_details())

        # åº•éƒ¨
        report.append(self._generate_footer())

        return '\n\n'.join(report)

    def _generate_header(self) -> str:
        """ç”ŸæˆæŠ¥å‘Šå¤´éƒ¨"""
        lines = [
            f"# ä»£ç å¥åº·æ—¥æŠ¥",
            "",
            f"**æ—¥æœŸ**: {self.report_date}",
            f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "---"
        ]
        return '\n'.join(lines)

    def _generate_basic_metrics(self) -> str:
        """ç”ŸæˆåŸºç¡€æŒ‡æ ‡"""
        total_commits = 0
        total_files = 0
        active_repos = 0
        active_authors = set()
        author_commit_counts = defaultdict(int)

        for analyzer in self.analyzers:
            commits = analyzer['git'].get_commits(self.since_time, self.until_time)
            if commits:
                total_commits += len(commits)
                active_repos += 1
                for commit in commits:
                    active_authors.add(commit['author'])
                    author_commit_counts[commit['author']] += 1
                    total_files += len(commit['files'])

        lines = [
            "### ğŸ“Š åŸºæœ¬æ•°æ®",
            "",
            "| æŒ‡æ ‡ | æ•°å€¼ |",
            "|------|------|",
            f"| æäº¤æ¬¡æ•° | **{total_commits}** æ¬¡ |",
            f"| æ´»è·ƒå¼€å‘è€… | **{len(active_authors)}** äºº |",
            f"| æ¶‰åŠä»“åº“ | **{active_repos}** ä¸ª |",
            f"| ä¿®æ”¹æ–‡ä»¶æ•° | **{total_files}** ä¸ª |",
            ""
        ]

        if active_authors:
            lines.append(f"**æ´»è·ƒå¼€å‘è€…è¯¦æƒ…**:")
            lines.append("")
            # æŒ‰æäº¤æ¬¡æ•°æ’åº
            sorted_authors = sorted(author_commit_counts.items(), key=lambda x: x[1], reverse=True)
            for author, count in sorted_authors:
                lines.append(f"- {author} ({count} commits)")
            lines.append("")

        return '\n'.join(lines)

    def _generate_code_changes(self) -> str:
        """ç”Ÿæˆä»£ç å˜æ›´ç»Ÿè®¡"""
        total_added = 0
        total_deleted = 0
        large_commits = 0
        tiny_commits = 0
        repo_stats = []

        for analyzer in self.analyzers:
            commits = analyzer['git'].get_commits(self.since_time, self.until_time)
            repo_added = sum(c['lines_added'] for c in commits)
            repo_deleted = sum(c['lines_deleted'] for c in commits)

            if commits:
                repo_stats.append({
                    'name': analyzer['name'],
                    'commits': len(commits),
                    'added': repo_added,
                    'deleted': repo_deleted,
                    'net': repo_added - repo_deleted
                })

                # ç»Ÿè®¡å¤§æäº¤å’Œå¾®å°æäº¤
                for commit in commits:
                    total_change = commit['lines_added'] + commit['lines_deleted']
                    if total_change > self.config['thresholds']['large_commit']:
                        large_commits += 1
                    elif total_change < self.config['thresholds']['tiny_commit']:
                        tiny_commits += 1

            total_added += repo_added
            total_deleted += repo_deleted

        net_lines = total_added - total_deleted

        lines = [
            "### ğŸ“ˆ ä»£ç å˜æ›´é‡",
            "",
            "| æŒ‡æ ‡ | æ•°å€¼ |",
            "|------|------|",
            f"| æ–°å¢è¡Œæ•° | +{format_number(total_added)} è¡Œ |",
            f"| åˆ é™¤è¡Œæ•° | -{format_number(total_deleted)} è¡Œ |",
            f"| **å‡€å¢è¡Œæ•°** | **{'+' if net_lines >= 0 else ''}{format_number(net_lines)}** è¡Œ |",
            ""
        ]

        # æäº¤è´¨é‡åˆ†æ
        lines.extend([
            "### ğŸ“ æäº¤è´¨é‡",
            "",
            "| æŒ‡æ ‡ | æ•°å€¼ | çŠ¶æ€ |",
            "|------|------|------|",
            f"| å¤§æäº¤ (>{self.config['thresholds']['large_commit']}è¡Œ) | {large_commits} æ¬¡ | "
            f"{'ğŸ”´ è­¦å‘Š' if large_commits > 3 else 'ğŸŸ¢ æ­£å¸¸'} |",
            f"| å¾®å°æäº¤ (<{self.config['thresholds']['tiny_commit']}è¡Œ) | {tiny_commits} æ¬¡ | "
            f"{'ğŸŸ¡ å…³æ³¨' if tiny_commits > 5 else 'ğŸŸ¢ æ­£å¸¸'} |",
            ""
        ])

        # æŒ‰ä»“åº“ç»Ÿè®¡
        if repo_stats:
            lines.extend([
                "### ğŸ“¦ å„ä»“åº“å˜æ›´",
                "",
                "| ä»“åº“ | æäº¤ | æ–°å¢ | åˆ é™¤ | å‡€å¢ |",
                "|------|------|------|------|------|"
            ])

            repo_stats.sort(key=lambda x: x['net'], reverse=True)
            for stat in repo_stats:
                lines.append(
                    f"| {stat['name']} | {stat['commits']} | "
                    f"+{format_number(stat['added'])} | "
                    f"-{format_number(stat['deleted'])} | "
                    f"**{'+' if stat['net'] >= 0 else ''}{format_number(stat['net'])}** |"
                )
            lines.append("")

        return '\n'.join(lines)

    def _generate_risk_alerts(self) -> str:
        """ç”Ÿæˆé£é™©é¢„è­¦"""
        lines = []

        # 1. ä»£ç éœ‡è¡æ£€æµ‹
        lines.append("### 1ï¸âƒ£ ä»£ç éœ‡è¡æ£€æµ‹")
        lines.append("")

        all_churn_files = []
        total_churn_rate = 0
        repo_count = 0

        for analyzer in self.analyzers:
            churn_files, churn_rate = analyzer['churn'].analyze()
            if churn_files or churn_rate > 0:
                all_churn_files.extend([{**f, 'repo': analyzer['name']} for f in churn_files])
                total_churn_rate += churn_rate
                repo_count += 1

        avg_churn_rate = total_churn_rate / repo_count if repo_count > 0 else 0

        # éœ‡è¡ç‡è¯„çº§
        if avg_churn_rate >= 30:
            churn_status = "ğŸ”´ **é«˜é£é™©**"
        elif avg_churn_rate >= 10:
            churn_status = "ğŸŸ¡ **ä¸­é£é™©**"
        else:
            churn_status = "ğŸŸ¢ **ä½é£é™©**"

        lines.append(f"**éœ‡è¡ç‡**: {avg_churn_rate:.1f}% | çŠ¶æ€: {churn_status}")
        lines.append("")

        if all_churn_files:
            lines.append(f"**éœ‡è¡æ–‡ä»¶ TOP 5** (æœ€è¿‘{self.config['thresholds']['churn_days']}å¤©å†…ä¿®æ”¹â‰¥{self.config['thresholds']['churn_count']}æ¬¡):")
            lines.append("")
            lines.append("| ä»“åº“ | æ–‡ä»¶ | ä¿®æ”¹æ¬¡æ•° | æ¶‰åŠå¼€å‘è€… |")
            lines.append("|------|------|---------|-----------|")

            all_churn_files.sort(key=lambda x: x['count'], reverse=True)
            for f in all_churn_files[:5]:
                authors = ', '.join(f['authors'][:3])
                if len(f['authors']) > 3:
                    authors += f" ç­‰{len(f['authors'])}äºº"
                lines.append(f"| {f['repo']} | `{f['file']}` | {f['count']} | {authors} |")
            lines.append("")
        else:
            lines.append("âœ… æœªå‘ç°éœ‡è¡æ–‡ä»¶")
            lines.append("")

        # 2. è¿”å·¥ç‡æ£€æµ‹
        lines.append("### 2ï¸âƒ£ è¿”å·¥ç‡æ£€æµ‹")
        lines.append("")

        total_rework = 0
        total_added_for_rework = 0

        for analyzer in self.analyzers:
            rework_lines, added_lines, rework_rate = analyzer['rework'].analyze()
            total_rework += rework_lines
            total_added_for_rework += added_lines

        overall_rework_rate = (total_rework / total_added_for_rework * 100) if total_added_for_rework > 0 else 0

        # è¿”å·¥ç‡è¯„çº§
        if overall_rework_rate >= 30:
            rework_status = "ğŸ”´ **é«˜é£é™©**"
        elif overall_rework_rate >= 15:
            rework_status = "ğŸŸ¡ **ä¸­é£é™©**"
        else:
            rework_status = "ğŸŸ¢ **ä½é£é™©**"

        lines.append(f"**è¿”å·¥ç‡**: {overall_rework_rate:.1f}% | çŠ¶æ€: {rework_status}")
        lines.append(f"**è¿”å·¥ä»£ç **: {format_number(total_rework)} è¡Œ (æœ€è¿‘7å¤©æ–°å¢ä¸­æœ‰{self.config['thresholds']['rework_delete_days']}å¤©å†…è¢«åˆ é™¤)")
        lines.append("")

        # 3. é«˜å±æ–‡ä»¶é¢„è­¦
        lines.append("### 3ï¸âƒ£ é«˜å±æ–‡ä»¶é¢„è­¦")
        lines.append("")

        all_hotspots = []
        for analyzer in self.analyzers:
            hotspots = analyzer['hotspot'].analyze()
            all_hotspots.extend([{**h, 'repo': analyzer['name']} for h in hotspots])

        all_hotspots.sort(key=lambda x: x['risk_score'], reverse=True)
        high_risk_count = len([h for h in all_hotspots if h['risk_score'] >= 80])

        if all_hotspots:
            lines.append(f"**å‘ç°é«˜å±æ–‡ä»¶**: {len(all_hotspots)} ä¸ª (ä¸¥é‡: {high_risk_count})")
            lines.append("")
            lines.append("**TOP 5 é«˜å±æ–‡ä»¶**:")
            lines.append("")
            lines.append("| ä»“åº“ | æ–‡ä»¶ | é£é™©åˆ† | ä¿®æ”¹æ¬¡æ•° | å¤§å° | å¼€å‘è€… | æ ‡ç­¾ |")
            lines.append("|------|------|--------|---------|------|--------|------|")

            for h in all_hotspots[:5]:
                risk_emoji = "ğŸ”´" if h['risk_score'] >= 80 else "ğŸŸ " if h['risk_score'] >= 60 else "ğŸŸ¡"
                tags = ', '.join(h['tags']) if h['tags'] else "-"
                authors_display = f"{h['author_count']}äºº"

                lines.append(
                    f"| {h['repo']} | `{h['file']}` | {risk_emoji} {h['risk_score']:.0f} | "
                    f"{h['modify_count']} | {h['file_size']} è¡Œ | {authors_display} | {tags} |"
                )
            lines.append("")
        else:
            lines.append("âœ… æœªå‘ç°é«˜å±æ–‡ä»¶")
            lines.append("")

        # 4. å·¥ä½œæ—¶é—´å¼‚å¸¸
        lines.append("### 4ï¸âƒ£ å·¥ä½œæ—¶é—´å¼‚å¸¸")
        lines.append("")

        late_night_commits = []
        weekend_commits_list = []
        overtime_commits = []

        for analyzer in self.analyzers:
            commits = analyzer['git'].get_commits(self.since_time, self.until_time)
            for commit in commits:
                if is_late_night(commit['date'], self.config):
                    late_night_commits.append({
                        'author': commit['author'],
                        'time': commit['date'],
                        'repo': analyzer['name']
                    })
                if is_weekend(commit['date']):
                    weekend_commits_list.append({
                        'author': commit['author'],
                        'time': commit['date'],
                        'repo': analyzer['name']
                    })
                if is_overtime(commit['date'], self.config):
                    overtime_commits.append({
                        'author': commit['author'],
                        'time': commit['date'],
                        'repo': analyzer['name']
                    })

        if late_night_commits or weekend_commits_list or overtime_commits:
            # é£é™©æŒ‡æ ‡è¯´æ˜
            lines.append("**é£é™©æŒ‡æ ‡è¯´æ˜**:")
            lines.append("- â° åŠ ç­æäº¤: 18:00-21:00æäº¤ï¼Œå¯èƒ½æ’æœŸç´§å¼ ")
            lines.append("- ğŸŒ™ æ·±å¤œæäº¤: 22:00-06:00æäº¤ï¼Œå½±å“å¥åº·å’Œä»£ç è´¨é‡")
            lines.append("- ğŸ“… å‘¨æœ«å·¥ä½œ: å‘¨å…­/å‘¨æ—¥æäº¤ï¼Œå·¥ä½œç”Ÿæ´»å¤±è¡¡")
            lines.append("")

            # åŠ ç­æäº¤ç»Ÿè®¡
            if overtime_commits:
                lines.append(f"#### â° åŠ ç­æäº¤: {len(overtime_commits)} æ¬¡")
                lines.append("")
                lines.append("**æ—¶æ®µ**: 18:00-21:00 (æ™šé¤æ—¶é—´å)")
                lines.append("**å½±å“**: å¯èƒ½æ’æœŸè¾ƒç´§ï¼Œéœ€å…³æ³¨é¡¹ç›®è¿›åº¦")
                lines.append("")
                author_counts = defaultdict(int)
                for c in overtime_commits:
                    author_counts[c['author']] += 1
                top_authors = sorted(author_counts.items(), key=lambda x: x[1], reverse=True)
                lines.append(f"**æ¶‰åŠäººå‘˜**: {', '.join([f'{a}({c}æ¬¡)' for a, c in top_authors[:3]])}")
                lines.append("")
                lines.append("**å»ºè®®**:")
                lines.append("- è¯„ä¼°æ’æœŸæ˜¯å¦åˆç†ï¼Œæ˜¯å¦éœ€è¦è°ƒæ•´")
                lines.append("- å…³æ³¨å›¢é˜Ÿå·¥ä½œè´Ÿè·ï¼Œé¿å…æŒç»­åŠ ç­")
                lines.append("- ä¼˜åŒ–ä»»åŠ¡åˆ†é…ï¼Œæé«˜å¼€å‘æ•ˆç‡")
                lines.append("")

            # æ·±å¤œæäº¤ç»Ÿè®¡
            if late_night_commits:
                lines.append(f"#### ğŸŒ™ æ·±å¤œæäº¤: {len(late_night_commits)} æ¬¡")
                lines.append("")
                lines.append("**æ—¶æ®µ**: 22:00-06:00 (åº”è¯¥ä¼‘æ¯çš„æ—¶é—´)")
                lines.append("**å½±å“**: ä¸¥é‡å½±å“å¥åº·å’Œç¡çœ ï¼Œå¯èƒ½å¯¼è‡´ä»£ç è´¨é‡ä¸‹é™")
                lines.append("")
                author_counts = defaultdict(int)
                for c in late_night_commits:
                    author_counts[c['author']] += 1
                top_authors = sorted(author_counts.items(), key=lambda x: x[1], reverse=True)
                lines.append(f"**é«˜é¢‘äººå‘˜**: {', '.join([f'{a}({c}æ¬¡)' for a, c in top_authors[:3]])}")
                lines.append("")
                lines.append("**å¥åº·æé†’**:")
                lines.append("- ğŸš¨ **å¼ºçƒˆå»ºè®®**: ä¿è¯å……è¶³ç¡çœ ï¼Œé¿å…æ·±å¤œå·¥ä½œ")
                lines.append("- æ·±å¤œå·¥ä½œå®¹æ˜“å‡ºç°bugï¼Œå»ºè®®ç¬¬äºŒå¤©review")
                lines.append("- å¦‚æœæ˜¯ç´§æ€¥ä¿®å¤ï¼Œéœ€è¦åç»­è¡¥å……æµ‹è¯•")
                lines.append("- æŒç»­æ·±å¤œå·¥ä½œè¯·åŠæ—¶ä¸ç®¡ç†å±‚æ²Ÿé€š")
                lines.append("")

            # å‘¨æœ«å·¥ä½œç»Ÿè®¡
            if weekend_commits_list:
                lines.append(f"#### ğŸ“… å‘¨æœ«å·¥ä½œ: {len(weekend_commits_list)} æ¬¡")
                lines.append("")
                lines.append("**æ—¶æ®µ**: å‘¨å…­/å‘¨æ—¥")
                lines.append("**å½±å“**: å·¥ä½œç”Ÿæ´»å¤±è¡¡ï¼Œé•¿æœŸå½±å“å›¢é˜Ÿå£«æ°”")
                lines.append("")
                author_counts = defaultdict(int)
                for c in weekend_commits_list:
                    author_counts[c['author']] += 1
                top_authors = sorted(author_counts.items(), key=lambda x: x[1], reverse=True)
                lines.append(f"**å‚ä¸äººå‘˜**: {', '.join([f'{a}({c}æ¬¡)' for a, c in top_authors[:3]])}")
                lines.append("")
                lines.append("**å»ºè®®**:")
                lines.append("- åˆç†å®‰æ’å·¥ä½œï¼Œé¿å…å‘¨æœ«åŠ ç­æˆä¸ºå¸¸æ€")
                lines.append("- å¦‚æœ‰ç´§æ€¥æƒ…å†µï¼Œå»ºè®®åç»­è°ƒä¼‘")
                lines.append("- è¯„ä¼°æ˜¯å¦éœ€è¦å¢åŠ äººåŠ›æˆ–å»¶é•¿æ’æœŸ")
                lines.append("")

            # æ•´ä½“å»ºè®®
            lines.append("**æ•´ä½“å»ºè®®**: å…³æ³¨å›¢é˜Ÿå·¥ä½œå‹åŠ›ï¼Œè¯„ä¼°æ’æœŸåˆç†æ€§ï¼Œä¿æŒå·¥ä½œç”Ÿæ´»å¹³è¡¡")
        else:
            lines.append("âœ… å·¥ä½œæ—¶é—´æ­£å¸¸ï¼Œæ— åŠ ç­/æ·±å¤œ/å‘¨æœ«æäº¤")

        lines.append("")

        return '\n'.join(lines)

    def _generate_health_score(self) -> str:
        """ç”Ÿæˆå¥åº·è¯„åˆ†"""
        # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
        total_commits = 0
        large_commits = 0
        all_commits = []
        late_night = 0
        weekend = 0

        for analyzer in self.analyzers:
            commits = analyzer['git'].get_commits(self.since_time, self.until_time)
            all_commits.extend(commits)
            total_commits += len(commits)

            for commit in commits:
                total_change = commit['lines_added'] + commit['lines_deleted']
                if total_change > self.config['thresholds']['large_commit']:
                    large_commits += 1
                if is_late_night(commit['date'], self.config):
                    late_night += 1
                if is_weekend(commit['date']):
                    weekend += 1

        # è®¡ç®—éœ‡è¡ç‡å’Œè¿”å·¥ç‡
        total_churn_rate = 0
        total_rework_rate = 0
        repo_count = 0

        all_hotspots = []

        for analyzer in self.analyzers:
            churn_files, churn_rate = analyzer['churn'].analyze()
            rework_lines, added_lines, rework_rate = analyzer['rework'].analyze()
            hotspots = analyzer['hotspot'].analyze()

            total_churn_rate += churn_rate
            total_rework_rate += rework_rate
            all_hotspots.extend(hotspots)
            repo_count += 1

        avg_churn_rate = total_churn_rate / repo_count if repo_count > 0 else 0
        avg_rework_rate = total_rework_rate / repo_count if repo_count > 0 else 0

        message_quality = calculate_message_quality(all_commits)
        high_risk_files = len([h for h in all_hotspots if h['risk_score'] >= 60])

        # æ„å»ºæŒ‡æ ‡å­—å…¸
        metrics = {
            'large_commits': large_commits,
            'churn_rate': avg_churn_rate,
            'rework_rate': avg_rework_rate,
            'message_quality': message_quality,
            'late_night_commits': late_night,
            'weekend_commits': weekend,
            'high_risk_files': high_risk_files
        }

        # è®¡ç®—å¥åº·åˆ†
        calculator = HealthScoreCalculator(self.config['thresholds'])
        score, deductions = calculator.calculate(metrics)
        emoji, level = calculator.get_level(score)

        lines = [
            f"### {emoji} ç»¼åˆè¯„åˆ†: {score} åˆ† ({level})",
            ""
        ]

        # è¯„åˆ†è¯´æ˜
        lines.append("**è¯„åˆ†è¯´æ˜**:")
        lines.append("- ğŸŸ¢ ä¼˜ç§€ (â‰¥80åˆ†): ä»£ç è´¨é‡é«˜ï¼Œå·¥ä½œæ—¶é—´å¥åº·")
        lines.append("- ğŸŸ¡ è‰¯å¥½ (60-79åˆ†): æœ‰æ”¹è¿›ç©ºé—´ï¼Œå»ºè®®å…³æ³¨æ‰£åˆ†é¡¹")
        lines.append("- ğŸŸ  è­¦å‘Š (40-59åˆ†): å­˜åœ¨æ˜æ˜¾é—®é¢˜ï¼Œéœ€åŠæ—¶æ”¹è¿›")
        lines.append("- ğŸ”´ å±é™© (<40åˆ†): ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ç«‹å³å¤„ç†")
        lines.append("")

        # è¯„åˆ†æ„æˆè¡¨æ ¼
        lines.append("**è¯„åˆ†æ„æˆ**:")
        lines.append("")
        lines.append("| è¯„åˆ†ç»´åº¦ | å½“å‰çŠ¶æ€ | å½±å“ | è¯´æ˜ |")
        lines.append("|---------|---------|------|------|")

        # å¤§æäº¤
        if large_commits > 0:
            lines.append(f"| å¤§æäº¤æ¬¡æ•° | {large_commits}æ¬¡ | -{large_commits * 5}åˆ† | å•æ¬¡å˜æ›´>500è¡Œï¼Œå»ºè®®æ‹†åˆ† |")
        else:
            lines.append(f"| å¤§æäº¤æ¬¡æ•° | 0æ¬¡ | +0åˆ† | âœ… æäº¤ç²’åº¦é€‚ä¸­ |")

        # éœ‡è¡ç‡
        if avg_churn_rate > 30:
            lines.append(f"| ä»£ç éœ‡è¡ç‡ | {avg_churn_rate:.1f}% | -20åˆ† | é¢‘ç¹ä¿®æ”¹åŒä¸€æ–‡ä»¶ï¼Œä»£ç ä¸ç¨³å®š |")
        elif avg_churn_rate > 10:
            lines.append(f"| ä»£ç éœ‡è¡ç‡ | {avg_churn_rate:.1f}% | -10åˆ† | æœ‰ä¸€å®šéœ‡è¡ï¼Œå»ºè®®ä¼˜åŒ–è®¾è®¡ |")
        else:
            lines.append(f"| ä»£ç éœ‡è¡ç‡ | {avg_churn_rate:.1f}% | +0åˆ† | âœ… ä»£ç ç¨³å®š |")

        # è¿”å·¥ç‡
        if avg_rework_rate > 30:
            lines.append(f"| ä»£ç è¿”å·¥ç‡ | {avg_rework_rate:.1f}% | -15åˆ† | å¤§é‡è¿”å·¥ï¼Œéœ€æ±‚æˆ–è®¾è®¡æœ‰é—®é¢˜ |")
        elif avg_rework_rate > 15:
            lines.append(f"| ä»£ç è¿”å·¥ç‡ | {avg_rework_rate:.1f}% | -8åˆ† | æœ‰è¿”å·¥ç°è±¡ï¼Œå»ºè®®è¯„å®¡æœºåˆ¶ |")
        else:
            lines.append(f"| ä»£ç è¿”å·¥ç‡ | {avg_rework_rate:.1f}% | +0åˆ† | âœ… è¿”å·¥ç‡ä½ |")

        # æäº¤ä¿¡æ¯è´¨é‡
        if message_quality < 60:
            lines.append(f"| æäº¤ä¿¡æ¯è´¨é‡ | {message_quality:.0f}% | -10åˆ† | æäº¤ä¿¡æ¯ä¸è§„èŒƒ |")
        else:
            lines.append(f"| æäº¤ä¿¡æ¯è´¨é‡ | {message_quality:.0f}% | +0åˆ† | âœ… æäº¤ä¿¡æ¯è‰¯å¥½ |")

        # å·¥ä½œæ—¶é—´
        abnormal_commits = late_night + weekend
        if abnormal_commits > 0:
            lines.append(f"| å·¥ä½œæ—¶é—´å¥åº· | {abnormal_commits}æ¬¡å¼‚å¸¸ | -{abnormal_commits * 2}åˆ† | æ·±å¤œ/å‘¨æœ«å·¥ä½œï¼Œæ³¨æ„ä¼‘æ¯ |")
        else:
            lines.append(f"| å·¥ä½œæ—¶é—´å¥åº· | æ­£å¸¸ | +0åˆ† | âœ… å·¥ä½œæ—¶é—´å¥åº· |")

        # é«˜å±æ–‡ä»¶
        if high_risk_files > 0:
            deduction_hr = min(high_risk_files * 3, 15)
            lines.append(f"| é«˜å±æ–‡ä»¶æ•°é‡ | {high_risk_files}ä¸ª | -{deduction_hr}åˆ† | å­˜åœ¨é«˜å¤æ‚åº¦/é«˜ä¿®æ”¹é¢‘æ¬¡æ–‡ä»¶ |")
        else:
            lines.append(f"| é«˜å±æ–‡ä»¶æ•°é‡ | 0ä¸ª | +0åˆ† | âœ… æ— é«˜å±æ–‡ä»¶ |")

        lines.append("")

        # å¦‚æœæœ‰æ‰£åˆ†ï¼Œæ˜¾ç¤ºæ”¹è¿›å»ºè®®
        if score < 100:
            lines.append("**æ”¹è¿›å»ºè®®**:")
            lines.append("")
            if large_commits > 0:
                lines.append("- ğŸ“¦ **å‡å°‘å¤§æäº¤**: å°†å¤§å‹å˜æ›´æ‹†åˆ†ä¸ºå¤šä¸ªå°æäº¤ï¼Œæ¯æ¬¡åªåšä¸€ä»¶äº‹")
            if avg_churn_rate > 10:
                lines.append("- ğŸ”„ **é™ä½éœ‡è¡ç‡**: ä¼˜åŒ–ä»£ç è®¾è®¡ï¼Œå‡å°‘é¢‘ç¹ä¿®æ”¹åŒä¸€æ–‡ä»¶")
            if avg_rework_rate > 15:
                lines.append("- âš™ï¸ **å‡å°‘è¿”å·¥**: åŠ å¼ºéœ€æ±‚è¯„å®¡å’Œè®¾è®¡è¯„å®¡ï¼Œé™ä½è¿”å·¥ç‡")
            if message_quality < 60:
                lines.append("- ğŸ“ **è§„èŒƒæäº¤ä¿¡æ¯**: ä½¿ç”¨æœ‰æ„ä¹‰çš„æäº¤ä¿¡æ¯ï¼Œè¯´æ˜ä¿®æ”¹åŸå› ")
            if abnormal_commits > 0:
                lines.append("- ğŸ˜´ **æ³¨æ„å·¥ä½œæ—¶é—´**: é¿å…æ·±å¤œå’Œå‘¨æœ«å·¥ä½œï¼Œä¿æŒå·¥ä½œç”Ÿæ´»å¹³è¡¡")
            if high_risk_files > 0:
                lines.append("- ğŸš¨ **é‡æ„é«˜å±æ–‡ä»¶**: ä¼˜å…ˆå¤„ç†é«˜å¤æ‚åº¦æˆ–é«˜ä¿®æ”¹é¢‘æ¬¡çš„æ–‡ä»¶")
            lines.append("")

        # è¶‹åŠ¿å¯¹æ¯”ï¼ˆç®€åŒ–ç‰ˆï¼šä¸æ˜¨å¤©å¯¹æ¯”ï¼‰
        lines.append("**è¶‹åŠ¿**: éœ€è¦ç§¯ç´¯å†å²æ•°æ®")
        lines.append("")

        return '\n'.join(lines)

    def _generate_commit_details(self) -> str:
        """ç”Ÿæˆæäº¤è¯¦æƒ…"""
        all_commits = []

        for analyzer in self.analyzers:
            commits = analyzer['git'].get_commits(self.since_time, self.until_time)
            for commit in commits:
                all_commits.append({
                    **commit,
                    'repo': analyzer['name']
                })

        if not all_commits:
            return "ä»Šæ—¥æ— æäº¤è®°å½•"

        # æŒ‰ä½œè€…åˆ†ç»„
        author_commits = defaultdict(list)
        for commit in all_commits:
            author_commits[commit['author']].append(commit)

        lines = []

        for author, commits in sorted(author_commits.items()):
            author_added = sum(c['lines_added'] for c in commits)
            author_deleted = sum(c['lines_deleted'] for c in commits)
            author_net = author_added - author_deleted

            lines.append(f"### ğŸ‘¤ {author}")
            lines.append(f"æäº¤: {len(commits)} æ¬¡ | æ–°å¢: +{format_number(author_added)} | åˆ é™¤: -{format_number(author_deleted)} | å‡€å¢: {'+' if author_net >= 0 else ''}{format_number(author_net)}")
            lines.append("")

            for commit in commits:
                time = parse_iso_datetime(commit['date'])
                time_str = time.strftime("%H:%M")
                net = commit['lines_added'] - commit['lines_deleted']

                lines.append(
                    f"- [{commit['repo']}] {time_str} | "
                    f"+{commit['lines_added']}/-{commit['lines_deleted']} ({'+' if net >= 0 else ''}{net}) | "
                    f"{commit['message'][:60]}"
                )

            lines.append("")

        return '\n'.join(lines)

    def _generate_footer(self) -> str:
        """ç”ŸæˆæŠ¥å‘Šåº•éƒ¨"""
        lines = [
            "---",
            "",
            "**ğŸ“Œ è¯´æ˜**:",
            "- æ•°æ®æ¥æº: Git æäº¤å†å²",
            f"- ç»Ÿè®¡èŒƒå›´: {self.report_date} 00:00 - 23:59",
            "- æ›´æ–°é¢‘ç‡: æ¯æ—¥è‡ªåŠ¨ç”Ÿæˆ",
            "",
            "*ç”±ä»£ç å¥åº·ç›‘æ§ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*"
        ]
        return '\n'.join(lines)


def main():
    """ä¸»å‡½æ•°"""
    # è·å–é…ç½®æ–‡ä»¶è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    config_path = os.path.join(project_root, 'config.yaml')

    # è·å–æ—¥æœŸå‚æ•°
    report_date = sys.argv[1] if len(sys.argv) > 1 else None

    # ç”ŸæˆæŠ¥å‘Š
    generator = DailyReportGenerator(config_path, report_date)
    report = generator.generate()

    # è¾“å‡ºåˆ°æ–‡ä»¶
    report_date_str = report_date or datetime.now().strftime("%Y-%m-%d")
    output_dir = os.path.join(project_root, 'reports', 'daily')
    os.makedirs(output_dir, exist_ok=True)

    output_file = os.path.join(output_dir, f'{report_date_str}.md')
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"âœ… æ—¥æŠ¥å·²ç”Ÿæˆ: {output_file}")

    # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
    print("\n" + "=" * 80 + "\n")
    print(report)


if __name__ == "__main__":
    main()
